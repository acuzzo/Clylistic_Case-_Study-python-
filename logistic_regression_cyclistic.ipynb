{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import precision_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>...</th>\n",
       "      <th>member_casual</th>\n",
       "      <th>file</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>ride_length</th>\n",
       "      <th>ride_km</th>\n",
       "      <th>rider_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EC2DE40644C6B0F4</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-05-23 23:06:58</td>\n",
       "      <td>2022-05-23 23:40:19</td>\n",
       "      <td>Wabash Ave &amp; Grand Ave</td>\n",
       "      <td>TA1307000117</td>\n",
       "      <td>Halsted St &amp; Roscoe St</td>\n",
       "      <td>TA1309000025</td>\n",
       "      <td>41.891466</td>\n",
       "      <td>-87.626761</td>\n",
       "      <td>...</td>\n",
       "      <td>member</td>\n",
       "      <td>202205-divvy-tripdata.csv</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>2022</td>\n",
       "      <td>Monday</td>\n",
       "      <td>23</td>\n",
       "      <td>33.35</td>\n",
       "      <td>6.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1C31AD03897EE385</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-05-11 08:53:28</td>\n",
       "      <td>2022-05-11 09:31:22</td>\n",
       "      <td>DuSable Lake Shore Dr &amp; Monroe St</td>\n",
       "      <td>13300</td>\n",
       "      <td>Field Blvd &amp; South Water St</td>\n",
       "      <td>15534</td>\n",
       "      <td>41.880958</td>\n",
       "      <td>-87.616743</td>\n",
       "      <td>...</td>\n",
       "      <td>member</td>\n",
       "      <td>202205-divvy-tripdata.csv</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>2022</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>8</td>\n",
       "      <td>37.90</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ride_id rideable_type           started_at             ended_at  \\\n",
       "0  EC2DE40644C6B0F4  classic_bike  2022-05-23 23:06:58  2022-05-23 23:40:19   \n",
       "1  1C31AD03897EE385  classic_bike  2022-05-11 08:53:28  2022-05-11 09:31:22   \n",
       "\n",
       "                  start_station_name start_station_id  \\\n",
       "0             Wabash Ave & Grand Ave     TA1307000117   \n",
       "1  DuSable Lake Shore Dr & Monroe St            13300   \n",
       "\n",
       "              end_station_name end_station_id  start_lat  start_lng  ...  \\\n",
       "0       Halsted St & Roscoe St   TA1309000025  41.891466 -87.626761  ...   \n",
       "1  Field Blvd & South Water St          15534  41.880958 -87.616743  ...   \n",
       "\n",
       "   member_casual                       file month day  year  day_of_week  \\\n",
       "0         member  202205-divvy-tripdata.csv     5  23  2022       Monday   \n",
       "1         member  202205-divvy-tripdata.csv     5  11  2022    Wednesday   \n",
       "\n",
       "   start_hour ride_length  ride_km  rider_speed  \n",
       "0          23       33.35     6.30          0.0  \n",
       "1           8       37.90     0.61          0.0  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('output.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 \n",
    "\n",
    "initial preprocessing such as handing missing data and encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove missing data from \n",
    "df.dropna(subset=['ride_km', 'rider_speed'], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target: 'member_casual' to binary format\n",
    "df['is_member'] = (df['member_casual'] == 'member').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select independent variables\n",
    "categorical_features = ['rideable_type', 'day_of_week']\n",
    "numeric_features = ['start_hour', 'ride_length', 'ride_km', 'rider_speed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical variables\n",
    "# drop first = true to avoid multicollinearity\n",
    "\n",
    "# One-hot encode 'rideable_type'\n",
    "df = pd.get_dummies(df, columns=['rideable_type'], prefix='rideable', drop_first=True)\n",
    "\n",
    "# One-hot encode 'day_of_week'\n",
    "df = pd.get_dummies(df, columns=['day_of_week'], prefix='day', drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine your categorical and numeric features\n",
    "features = numeric_features + list(df.columns[df.columns.str.startswith('rideable_')]) + list(df.columns[df.columns.str.startswith('day_')])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Elimination (RFE) to select only the most important features for training and prediction processes in the logistic regression model. The result should be a model that is just as effective but potentially simpler and more efficient than a model that uses all available features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['day_Saturday',\n",
       " 'day_Sunday',\n",
       " 'ride_length',\n",
       " 'rideable_docked_bike',\n",
       " 'rideable_electric_bike']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select independent variables\n",
    "X = df[features]\n",
    "\n",
    "# Select dependent variable\n",
    "y = df['is_member']\n",
    "\n",
    "# Split the data into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize logistic regression model with increased number of iterations\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create preprocessor to only scale numeric features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', scaler, numeric_features)],\n",
    "    remainder='passthrough')\n",
    "\n",
    "# Fit and transform X_train\n",
    "X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Transform X_test\n",
    "X_test_scaled = preprocessor.transform(X_test)\n",
    "\n",
    "# Apply RFE for feature selection\n",
    "rfe = RFE(estimator=log_reg, n_features_to_select=5)\n",
    "\n",
    "rfe.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the features sorted by their rank\n",
    "features_sorted_by_rank = sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), features))\n",
    "\n",
    "# Select top features\n",
    "top_features = [feature for rank, feature in features_sorted_by_rank if rank == 1]\n",
    "top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.36      0.48    510082\n",
      "           1       0.64      0.88      0.75    666997\n",
      "\n",
      "    accuracy                           0.66   1177079\n",
      "   macro avg       0.68      0.62      0.61   1177079\n",
      "weighted avg       0.67      0.66      0.63   1177079\n",
      "\n",
      "               Predicted Casual  Predicted Member\n",
      "Actual Casual            184730            325352\n",
      "Actual Member             76777            590220\n"
     ]
    }
   ],
   "source": [
    "# Fit the model using top features\n",
    "log_reg.fit(X_train_scaled[:, rfe.support_], y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = log_reg.predict(X_test_scaled[:, rfe.support_])\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "confusion_df = pd.DataFrame(conf_matrix, index=['Actual Casual', 'Actual Member'], columns=['Predicted Casual', 'Predicted Member'])\n",
    "print(confusion_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.6578013521618788\n",
      "Training Precision: 0.6441237937977615\n",
      "Training Recall: 0.8850641666469876\n",
      "Training F1: 0.7456125780761531\n",
      "\n",
      "Test Accuracy: 0.6583670254927664\n",
      "Test Precision: 0.6446461883937036\n",
      "Test Recall: 0.8848915362437912\n",
      "Test F1: 0.7459011265859498\n"
     ]
    }
   ],
   "source": [
    "# compare accuracy scores between train and test to check if there is over fitting\n",
    "\n",
    "# Make predictions using the training data\n",
    "y_train_pred = log_reg.predict(X_train_scaled[:, rfe.support_])\n",
    "\n",
    "# Calculate performance metrics for the training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_precision = precision_score(y_train, y_train_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate performance metrics for the test data\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "test_precision = precision_score(y_test, y_pred)\n",
    "test_recall = recall_score(y_test, y_pred)\n",
    "test_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(f\"Training Accuracy: {train_accuracy}\")\n",
    "print(f\"Training Precision: {train_precision}\")\n",
    "print(f\"Training Recall: {train_recall}\")\n",
    "print(f\"Training F1: {train_f1}\")\n",
    "\n",
    "print(f\"\\nTest Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "print(f\"Test Recall: {test_recall}\")\n",
    "print(f\"Test F1: {test_f1}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to compare performance of the model trained on all the features to evaluate whether feature selection has improved the model performance or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.38      0.50    510082\n",
      "           1       0.65      0.88      0.75    666997\n",
      "\n",
      "    accuracy                           0.66   1177079\n",
      "   macro avg       0.68      0.63      0.62   1177079\n",
      "weighted avg       0.68      0.66      0.64   1177079\n",
      "\n",
      "               Predicted Casual  Predicted Member\n",
      "Actual Casual            195719            314363\n",
      "Actual Member             80139            586858\n"
     ]
    }
   ],
   "source": [
    "# Select independent variables\n",
    "X = df[features]\n",
    "\n",
    "# Select dependent variable\n",
    "y = df['is_member']\n",
    "\n",
    "# Split the data into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize logistic regression model \n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create preprocessor to only scale numeric features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', scaler, numeric_features)],\n",
    "    remainder='passthrough')\n",
    "\n",
    "# Fit and transform X_train\n",
    "X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Transform X_test\n",
    "X_test_scaled = preprocessor.transform(X_test)\n",
    "\n",
    "# Fit the model using top features\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "# Make predictions using the training data\n",
    "y_train_pred = log_reg.predict(X_train_scaled)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "confusion_df = pd.DataFrame(conf_matrix, index=['Actual Casual', 'Actual Member'], columns=['Predicted Casual', 'Predicted Member'])\n",
    "print(confusion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.664235292818318\n",
      "Training Precision: 0.6506272404910608\n",
      "Training Recall: 0.8799247625119995\n",
      "Training F1: 0.7481000566457584\n",
      "\n",
      "Test Accuracy: 0.6648466245681046\n",
      "Test Precision: 0.6511810088757364\n",
      "Test Recall: 0.8798510338127458\n",
      "Test F1: 0.7484393113712506\n"
     ]
    }
   ],
   "source": [
    "# compare accuracy scores between train and test to check if there is over fitting\n",
    "\n",
    "# Calculate performance metrics for the training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_precision = precision_score(y_train, y_train_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate performance metrics for the test data\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "test_precision = precision_score(y_test, y_pred)\n",
    "test_recall = recall_score(y_test, y_pred)\n",
    "test_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(f\"Training Accuracy: {train_accuracy}\")\n",
    "print(f\"Training Precision: {train_precision}\")\n",
    "print(f\"Training Recall: {train_recall}\")\n",
    "print(f\"Training F1: {train_f1}\")\n",
    "\n",
    "print(f\"\\nTest Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "print(f\"Test Recall: {test_recall}\")\n",
    "print(f\"Test F1: {test_f1}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results suggest that the model has decent performance, but there's room for improvement. The model appears to be better at identifying \"member\" instances (higher recall for class 1), but struggles more with identifying \"casual\" instances (lower recall for class 0).\n",
    "\n",
    "A possible interpretation is that the model tends to over-predict the \"member\" class. \n",
    "\n",
    "There is an imbalance in class dataset where member = 3334816 and casual = 2550575. The recall for 'casual' users in the model was relatively low compared to 'member' users, which might be a sign that the model is being influenced by the class imbalance.\n",
    "\n",
    "Another thing I could do is collect more informative features, or try different kinds of models, for example Random Forest.\n",
    "\n",
    "Feature selection didn't change the performance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_member\n",
       "1    3334816\n",
       "0    2550575\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_member'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
